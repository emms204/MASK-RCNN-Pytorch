# MASK-RCNN-Pytorch
Mask RCNN from Scratch Using Pytorch

Step by Step Explanation of the Paper

The Mask R-CNN paper introduces a deep learning architecture for object detection and segmentation. Here is a brief overview of the steps involved in the approach:

    The input image is passed through a convolutional neural network (CNN) backbone to generate a feature map.
    The feature map is fed into a Region Proposal Network (RPN), which generates a set of object proposals, each consisting of a bounding box and an objectness score.
    The proposals are refined using a RoI (Region of Interest) pooling layer, which extracts fixed-size feature maps for each proposal.
    The RoI feature maps are fed into a series of fully connected layers, which perform classification and bounding box regression to refine the object proposals.
    In addition to object detection, the architecture also includes a branch for pixel-wise segmentation, which predicts a binary mask for each object proposal.
    The segmentation branch is implemented using a fully convolutional network (FCN) architecture, which takes the RoI feature maps as input and produces a segmentation mask of the same size as the RoI.
    During training, the loss function includes terms for object detection, bounding box regression, and segmentation. The model is trained end-to-end using stochastic gradient descent.

Model Architecture

The Mask R-CNN architecture is built on top of the Faster R-CNN object detection framework. The main components of the architecture are:

    CNN Backbone: A deep convolutional neural network is used to extract features from the input image. The authors use ResNet-50 as the backbone network in their experiments.
    Region Proposal Network (RPN): The RPN generates a set of object proposals, each consisting of a bounding box and an objectness score. The RPN is trained to predict object proposals that have high overlap with ground-truth bounding boxes.
    RoI Pooling: The RoI pooling layer extracts fixed-size feature maps for each object proposal, which can be fed into a fully connected network for object detection and bounding box regression.
    Object Detection and Bounding Box Regression: The RoI feature maps are fed into a series of fully connected layers, which predict the object class and refine the bounding box coordinates for each object proposal.
    Mask Prediction: In addition to object detection, the architecture includes a branch for pixel-wise segmentation, which predicts a binary mask for each object proposal. The segmentation branch is implemented using a fully convolutional network (FCN) architecture.

Training Loop and Loss Function

The model is trained end-to-end using stochastic gradient descent with backpropagation. The loss function used during training includes three terms:

    RPN Classification Loss: The RPN is trained to predict object proposals that have high overlap with ground-truth bounding boxes. The RPN classification loss encourages the RPN to predict a high objectness score for positive anchors (anchors with high overlap with ground-truth bounding boxes) and a low objectness score for negative anchors (anchors with low overlap with ground-truth bounding boxes).
    RPN Regression Loss: The RPN is also trained to refine the coordinates of the object proposals. The RPN regression loss encourages the RPN to predict bounding box coordinates that are close to the ground-truth bounding boxes.
    Object Detection and Segmentation Loss: The object detection and segmentation branches are trained using a multi-task loss function, which includes terms for object detection, bounding box regression, and segmentation. The object detection loss encourages the network to predict the correct object class for each proposal. The bounding box regression loss encourages the network to refine the bounding box coordinates for each proposal. 

Model Sections Explained:
CNN Backbone:

    The input image is first passed through a CNN backbone, which is used to extract features from the image. The authors of the paper use ResNet-50 as the backbone network in their experiments, but other architectures such as VGG and Inception can also be used. The output of the backbone network is a feature map that preserves the spatial resolution of the input image but has reduced dimensions.

Region Proposal Network (RPN):

    The RPN is responsible for generating object proposals based on the feature map generated by the CNN backbone. The RPN consists of a set of convolutional layers that predict a set of anchor boxes for each pixel in the feature map. Each anchor box has a predefined aspect ratio and scale, and the RPN predicts the offset and size adjustments needed to generate a bounding box that tightly encloses the object.

    The RPN also predicts an objectness score for each anchor box, which indicates the probability that the box contains an object of interest. The RPN is trained to predict object proposals that have high overlap with ground-truth bounding boxes.

RoI Pooling

    The RoI pooling layer extracts fixed-size feature maps for each object proposal generated by the RPN. The RoI pooling layer takes as input the feature map generated by the CNN backbone and the set of object proposals generated by the RPN. For each object proposal, the RoI pooling layer extracts a fixed-size feature map from the input feature map that can be fed into a fully connected network for object detection and bounding box regression.

Object Detection and Bounding Box Regression

    The RoI feature maps are fed into a series of fully connected layers, which perform classification and bounding box regression to refine the object proposals. The classification layer predicts the probability of each object class for each proposal, while the bounding box regression layer predicts the offset and size adjustments needed to refine the bounding box coordinates for each proposal.

Mask Prediction

    In addition to object detection and bounding box regression, the architecture also includes a branch for pixel-wise segmentation, which predicts a binary mask for each object proposal. The segmentation branch is implemented using a fully convolutional network (FCN) architecture, which takes the RoI feature maps as input and produces a segmentation mask of the same size as the RoI.

During training, the loss function includes terms for object detection, bounding box regression, and segmentation. The model is trained end-to-end using stochastic gradient descent.
